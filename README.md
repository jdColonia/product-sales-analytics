# ğŸ“Š Pipeline de AnÃ¡lisis Exploratorio de Datos

Pipeline de anÃ¡lisis exploratorio de datos (EDA) desarrollado con Apache Spark para el anÃ¡lisis de ventas de productos.

## âœ’ï¸ Autores

> - Juan David Colonia Aldana - A00395956
> - Miguel Ãngel Gonzalez Arango - A00395687

## ğŸ¯ Objetivo

Realizar un anÃ¡lisis exploratorio completo de datasets de ventas, incluyendo:

### 1. RevisiÃ³n Inicial del Dataset

- Estructura del dataset (registros, columnas, tipos de datos)
- IdentificaciÃ³n de valores faltantes o nulos
- DetecciÃ³n de registros duplicados

### 2. EstadÃ­sticas Descriptivas

**Variables NumÃ©ricas:**

- Medidas de tendencia central: media, mediana, moda
- Medidas de dispersiÃ³n: desviaciÃ³n estÃ¡ndar, rango
- Percentiles: Q1 (25%), Q2 (50%), Q3 (75%)
- DetecciÃ³n de valores atÃ­picos (outliers) mediante mÃ©todo IQR
- **Nota:** Los IDs (product_id, customer_id, category_id, store_id) NO se analizan con estadÃ­sticas descriptivas ya que carecen de significado estadÃ­stico

**Variables CategÃ³ricas:**

- Frecuencias absolutas y relativas
- DistribuciÃ³n por categorÃ­as
- AnÃ¡lisis de cardinalidad

**AnÃ¡lisis de IDs:**

- Cardinalidad (valores Ãºnicos)
- Frecuencias de apariciÃ³n (productos mÃ¡s vendidos, clientes mÃ¡s activos)
- DetecciÃ³n de nulos o inconsistencias

## ğŸ—ï¸ Estructura del Proyecto

```
product-sales-analytics/
â”œâ”€â”€ config/
â”‚   â””â”€â”€ spark_config.py          # ConfiguraciÃ³n de Spark
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ products/
â”‚   â”‚   â”œâ”€â”€ Categories.csv
â”‚   â”‚   â””â”€â”€ ProductCategory.csv
â”‚   â””â”€â”€ transactions/
â”‚       â””â”€â”€ *_Tran.csv
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py              # InicializaciÃ³n del paquete
â”‚   â”œâ”€â”€ data_loader.py           # Carga y preparaciÃ³n de datos
â”‚   â”œâ”€â”€ eda_analyzer.py          # Motor de anÃ¡lisis exploratorio
â”‚   â”œâ”€â”€ visualizer.py            # GeneraciÃ³n de grÃ¡ficas
â”‚   â”œâ”€â”€ pipeline.py              # Orquestador del pipeline
â”‚   â””â”€â”€ utils.py                 # Utilidades comunes
â”œâ”€â”€ output/                     # Resultados generados (JSON + PNG)
â”‚   â””â”€â”€ plots/                   # GrÃ¡ficas generadas
â”œâ”€â”€ main.py                      # Script principal de ejecuciÃ³n
â””â”€â”€ requirements.txt             # Dependencias del proyecto
```

## âš¡ InstalaciÃ³n

### Requisitos

- Python 3.10
- Java (requerido por Apache Spark)

### Pasos

```bash
# Activar entorno virtual
.\venv\Scripts\activate  # Windows
source venv/bin/activate # Linux/Mac

# Instalar dependencias
pip install -r requirements.txt
```

## ğŸš€ Uso

### EjecuciÃ³n del Pipeline

```bash
python main.py
```

El pipeline ejecutarÃ¡ automÃ¡ticamente:

1. AnÃ¡lisis de categorÃ­as de productos
2. AnÃ¡lisis de relaciÃ³n productos-categorÃ­as
3. AnÃ¡lisis de transacciones
4. AnÃ¡lisis de transacciones detalladas
5. GeneraciÃ³n automÃ¡tica de todas las visualizaciones

### ConfiguraciÃ³n

Para ajustar el tamaÃ±o de las muestras o configuraciÃ³n de Spark, editar:

- `config/spark_config.py` - ConfiguraciÃ³n de memoria y recursos de Spark
- `main.py` - TamaÃ±os de muestra para anÃ¡lisis

## ğŸ“Š Datasets Analizados

| Dataset         | DescripciÃ³n                         |
| --------------- | ----------------------------------- |
| Categories      | CatÃ¡logo de categorÃ­as de productos |
| ProductCategory | RelaciÃ³n productos-categorÃ­as       |
| Transactions    | Transacciones de ventas por tienda  |

## ğŸ“ Resultados

Los resultados del anÃ¡lisis se muestran en consola durante la ejecuciÃ³n. Las visualizaciones se guardan automÃ¡ticamente en:

### Visualizaciones (PNG)

```
output/plots/
â”œâ”€â”€ product_categories_category_distribution.png
â”œâ”€â”€ products_per_category_top_category_name.png
â”œâ”€â”€ transactions_top_customer_id.png
â”œâ”€â”€ transactions_temporal_trend.png
â”œâ”€â”€ transactions_exploded_top_product_id.png
â”œâ”€â”€ transactions_exploded_temporal_trend.png
â””â”€â”€ README.md
```

**Tipos de grÃ¡ficas generadas:**

- DistribuciÃ³n de productos por categorÃ­a (pie chart y barras)
- Top clientes con mÃ¡s transacciones (barras horizontales)
- Top productos mÃ¡s vendidos (barras horizontales)
- Tendencias temporales de transacciones (grÃ¡ficos de lÃ­nea)

## ğŸ”§ Arquitectura

### MÃ³dulos Principales

**data_loader.py**

- Carga de datos desde archivos CSV
- TransformaciÃ³n y preparaciÃ³n de datos
- GestiÃ³n de mÃºltiples fuentes de datos

**eda_analyzer.py**

- AnÃ¡lisis de estructura de datasets
- CÃ¡lculo de estadÃ­sticas descriptivas
- DetecciÃ³n de outliers y anomalÃ­as
- GeneraciÃ³n de reportes

**pipeline.py**

- OrquestaciÃ³n del flujo de anÃ¡lisis
- GestiÃ³n de recursos de Spark
- Control de ejecuciÃ³n y logging

**visualizer.py**

- GeneraciÃ³n automÃ¡tica de grÃ¡ficas
- VisualizaciÃ³n de frecuencias categÃ³ricas
- GrÃ¡ficos de tendencias temporales
- ExportaciÃ³n de imÃ¡genes en alta resoluciÃ³n

**utils.py**

- Funciones auxiliares
- Formateo de salida
- Utilidades comunes

## ğŸ› ï¸ TecnologÃ­as

- Apache Spark 3.5.0
- PySpark
- Python 3.8+
- Pandas 2.0.3
- NumPy 1.24.3
